# 🧹 Data Preprocessing Techniques and Data Splitting for Machine Learning

Welcome to the repository for our beginner-friendly machine learning workshop on **Data Preprocessing** and **Data Splitting**! 🎓

This hands-on tutorial is designed for students and early-stage ML practitioners to understand and implement key techniques to clean, prepare, and split data before training any machine learning model.

> 📌 **Workshop Format**: This tutorial is delivered as an interactive [Google Colab notebook](https://colab.research.google.com/), with step-by-step explanations, Python code, visualizations, and analysis.

---

## 📘 What You'll Learn

By following this tutorial, you'll gain an understanding of:

### 🔧 Data Preprocessing Techniques
- Handling missing values (mean, median, mode, dropping)
- Encoding categorical variables (One-Hot Encoding, Label Encoding)
- Feature scaling and normalization
- Outlier detection and treatment
- Feature engineering (creating new variables from existing ones)

### ✂️ Data Splitting Techniques
- Train/Test split and Train/Validation/Test split
- Stratified sampling for balanced splits
- K-Fold Cross-Validation and when to use it

---

## 📊 Dataset Used

We use the **Titanic dataset** from [Kaggle](https://www.kaggle.com/competitions/titanic), which contains demographic and passenger information from the Titanic shipwreck. This dataset is widely used for introductory ML and classification problems.

---

## 🚀 How to Use This Notebook

1. **Open the Colab notebook**  
   Click the "Open in Colab" button at the top of the .ipynb file.

2. **Run each cell step-by-step**  
   The code is organized with explanations before and after each section. No installation required — just run the cells.

3. **Experiment and learn**  
   Try tweaking code, adding your own preprocessing steps, or switching datasets to deepen your understanding.

---

## 📦 Dependencies

This notebook runs on Google Colab with the following common Python libraries:

- `pandas`
- `numpy`
- `matplotlib`
- `seaborn`
- `scikit-learn`

No additional setup is required.

---

## 👨‍🏫 About the Workshop

This notebook was created as part of a live workshop introducing foundational concepts in data preparation for ML. It is designed to help learners develop a strong understanding of **data hygiene**, model fairness, and generalization — all of which start with proper preprocessing.

---

## 🙌 Contributing

If you found this tutorial helpful or would like to contribute improvements, feel free to:
- Fork the repository
- Open issues for suggestions or bugs
- Submit pull requests with enhancements

---

## 👤 Author

**Pranav Bhartiya**

Machine Learning Student Network

University of California, Davis.  

---

**Happy Preprocessing! 🚀**
